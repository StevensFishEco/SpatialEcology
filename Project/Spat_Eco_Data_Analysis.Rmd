---
title: "Lab2_Assignment"
output: html_document
date: "2024-01-16"
---


### Packages ###

We will start by loading all of the packages that we will be using. Note that I have "turned off" all returns from this chunk. Therefore, if something does not load properly, you will not know unless you check.

```{r, echo = FALSE, warning = FALSE, message = FALSE}

require(tidyverse)
require(sf)
require(tigris)
require(geodata)
require(terra)
require(colorspace)
require(tidyterra)
require(ggnewscale)
require(cowplot)
require(ggspatial)
require(ggpubr)
require(gridExtra)
require(readr)
require(nhdplusTools)
require(devtools)
install_github('USEPA/StreamCatTools')
require(StreamCatTools)

require(dismo)
require(predicts)
require(mgcv)
require(maxnet)
require(spatialEco)
require(enmSdmX)

```

### Occurence data ###

These occurrence data are from a recently completed graduate project at the University of Arkansas, Pine Bluff (Hartman 2021). I have uploaded them to GitHub for the purposes of this project, but future use of these data will need to be approved by Maxwell Hartman (Arkansas Game and Fish Commission) and Steve Lochmann (University of Arkansas, Pine Bluff). This data is from an occupancy study, so there are both presences and absences in the dataset.

We will start by reading in the data from GitHub using the read_csv function in the readr package. We will then plot each location by "Present".

```{r}

PBlocs = read_csv("https://raw.githubusercontent.com/StevensFishEco/SpatialEcology/main/Project/Data/PalebackLocations.csv")

ggplot(PBlocs, aes(x=Longitude, y=Latitude, color = Present))+
  geom_point()

```

Now, we will have to manipulate the data to link each occurrence to a specific stream segment. First, we will make the location data a spatial object using the st_as_sf function in the sf package. Then, we will link each location with a COMID using the sc_get_comid function from the StreamCatTools package.

```{r}

# Make it a spatial object

PBlocsSf = st_as_sf(PBlocs, coords=c('Longitude', 'Latitude'), crs=4326)

# Lets quickly plot it (it will show each variable associated with the points)

plot(PBlocsSf)

# Lets make a dummy column to fill with COMIDs

PBlocsSf$COMID <- 0

# Here, we will get the centroid of each linestring

PBlocsSf <- st_centroid(PBlocsSf)

# This function links each point to a COMID

for (i in 1:nrow(PBlocsSf)){
  PBlocsSf[i, "COMID"] = sc_get_comid(PBlocsSf[i,])
}

```

### Basin and Flowlines ###

Our occurrences are now linked to a stream segment via the COMID.

Next, we will read in the basin polygon and flowlines and then link them to COMIDs so that we can retrieve environmental data across the entire basin. These data are from the National Hydrography Dataset (NHD) and are available for download from the USGS. I have uploaded the data to GitHub for this project. First, we will read in the basin polygon using the st_read function in the sf package. 

```{r}

# Read in basin polygon

Basin <- st_read("/vsicurl/https://raw.githubusercontent.com/StevensFishEco/SpatialEcology/main/Project/Data/Basin/WBDHU6.shp")

# Check the projection

st_crs(Basin)$proj4string

# Lets quickly plot it

plot(st_geometry(Basin))

```

Next, we will read in the flowlines using the st_read function in the sf package and make them sf objects using the st_as_sf functon in the sf package. The flowlines are from two different HUC 8 catchments, so they are packaged separately (we will combine them later). The two different catchments are the Ouachita Headwaters (St0101) and the Upper Oauchita (St0102).

```{r}

# Read in flowlines

St0101 <- st_read("/vsicurl/https://raw.githubusercontent.com/StevensFishEco/SpatialEcology/main/Project/Data/0101//NHDFlowline.shp")


St0102 <- st_read("/vsicurl/https://raw.githubusercontent.com/StevensFishEco/SpatialEcology/main/Project/Data/0102//NHDFlowline.shp")


# Remove Z and M ranges from stream segments (required to make them spatial objects)

St0101 = st_zm(St0101)
St0102 = st_zm(St0102)

# Make both sf objects

St0101<- st_as_sf(St0101)
St0102<- st_as_sf(St0102)

```

Next, we will get a COMID for each stream segment so that we can retrieve environmental data across the entire catchment. To do this, we will use the sc_get_comid function in the StreamCatTools package. 

To get a COMID for each stream segment, we need a point for each stream segment, but that point cannot be a node where two stream segments meet. To solve this issue, we will approximate the center of each stream segment with the st_centroid function in the sf package. The sc_get_comid function in the StreamCatTools package will return a linestring of COMIDs if ran on the entire object, so we will have to use a for-loop. We will then put the COMIDs back into the main spatial objects.

```{r}

# Get COMIDs for each stream segment in the Ouachita Headwaters catchment

tmp0101 <- st_centroid(St0101)
tmp0101$COMID <- 0

for (i in 1:nrow(tmp0101)){
  tmp0101[i, "COMID"] = sc_get_comid(tmp0101[i,])
}

# Get COMIDs for each stream segment in the Upper Ouachita catchment

tmp0102 <- st_centroid(St0102)
tmp0102$COMID <- 0

for (i in 1:nrow(tmp0102)){
  tmp0102[i, "COMID"] = sc_get_comid(tmp0102[i,])
}

# Put the COMIDs back to the flowlines

St0101$COMID <- tmp0101$COMID

St0102$COMID <- tmp0102$COMID


# How many are unique? So we have less than half of the total COMIDs for each basin... that is not good

summary(unique(St0101$COMID))
summary(unique(St0102$COMID))

```

#### Linking environmental data ####

Now that each stream segment has an associated COMID (even though they are not exact in this particular case), we can now link some environmental data to each stream segment. For this, we'll use the StreamCat database from the EPA through the StreamCatTools package. Note that any steam segment data identified by the COMID can now be linked to our stream segments (i.e., NHD VAA data).

```{r}

## Here, we are first getting environmental data from the StreamCat database with the sc_get_data function and then merging that data back into the main sf object by the COMID.

St0101var <- sc_get_data(comid = St0101$COMID, aoi='catchment', metric='BFI,Tmean8110,Precip8110,Elev,HUDen2010')

St0101f <- merge(St0101, St0101var, by = "COMID")


St0102var <- sc_get_data(comid = St0102$COMID, aoi='catchment', metric='BFI,Tmean8110,Precip8110,Elev,HUDen2010')

St0102f <- merge(St0102, St0102var, by = "COMID")


## Okay, now lets combine the two basins so we have just one object to work with (we could have done this earlier, but previous functions took a while to run even with the catchments separated).

EnvFull <- rbind(St0101f, St0102f)

# Lets quickly plot the flowlines to make sure that it still looks right.

# First, we will check the projections

st_crs(EnvFull)$proj4string
st_crs(PBlocsSf)$proj4string
PBlocsSf = st_transform(PBlocsSf, st_crs(EnvFull))

# Now, lets plot it

ggplot()+
  geom_sf(data = EnvFull, color = "lightblue") +
  geom_sf(data = PBlocsSf, aes(color = Present))

```


### Modeling ###

Now that we know everything looks good spatially, we will go ahead and do some habitat modeling. First, wewill need to separate our original occurrence data to present locations and absent locations. 

```{r}

# Break present and absent from PB data

PalePres = PBlocsSf %>% filter(Present==1)
PaleAbs = PBlocsSf %>% filter(Present==0)

presSegs <- EnvFull %>%
      filter(COMID %in% PalePres$COMID)

presSegs$Present = 1

```

Next, we will randomly select 200 stream segments to serve as background locations (i.e., pseudo-absences). Since we cannot exclude sampled sites with this method, we will have to manually check if any of the randomly-selected background segments were sampled in the occupancy study. If there are randomly-selected sites that were previously sampled, we will remove them. Finally, we will merge the present and background locations to fit our models.

```{r}

# Background points

set.seed(73)

backSegs <- sample_n(EnvFull, 200)

backSegs$Present <- 0

ggplot()+
  geom_sf(data = EnvFull) + 
  geom_sf(data = backSegs, color = "red") +
  geom_sf(data = presSegs, color='green')

# Were any previously-sampled stream segments randomly selected as background stream segments?

tmp <- st_equals(presSegs, backSegs)

# There is 1 randomly-selected stream segment that was previously selected, lets just delete it.

backSegs<- backSegs[-33,]

# Lets put the present and background stream segments together.

PresBackSegs = rbind(presSegs, backSegs)

# For some reason, the model was having issues with the data as a spatial object, so we will convert to a data frame.

PresBackSegs <- as.data.frame(PresBackSegs)

```

Now that we have a data frame of presence and background stream segments identifiable by COMID and associated with environmental data, we can actually fit a habitat model. Here, we are modeling with maximum entropy (i.e., MaxEnt) using the maxnet function in the maxnet package. Then, we will project the model over across the entire catchment using the predictMaxnet function in the enmSdmX package. Finally, we will put the model prediction back into the main sf object and plot the catchment by the model prediction.

```{r}

# The maxnet function needs a subset of locations that were occupied.

pbVect = PresBackSegs$Present

# The maxnet function also requires the environmental variables to be specified.

covs <- PresBackSegs %>% dplyr::select(WSAREASQKM:TMEAN8110CAT)

# Here, we will actually fit the MaxEnt model.

maxentModel = maxnet(p = pbVect,
                     data= covs,
                     regmult = 1,
                     classes='lqpht')

# Here, we will plot the regressions for each variable.

plot(maxentModel, type='logistic')

# Now, we will project the model across the catchment and plot to identify any potential outliers (recall that this is non-spatial data so it will be a basic scatter plot).

maxentMap = predictMaxNet(maxentModel, as.data.frame(EnvFull), type='logistic')

plot(maxentMap)

# Now, we will bind the model predictions to the spatial object so that we can plot the actual stream segments with the model prediction.

projected <- cbind(EnvFull, maxentMap)

# Here is the predicted habitat suitability across the catchment

ggplot()+
  geom_sf(data = st_geometry(Basin), fill = "gray95") +
  geom_sf(data = EnvFull, aes(color = maxentMap))

```


### Model performance and validation ###


Now that we have fit a MaxEnt model and projected it across the catchment, we can assess how well our model performs. 

```{r}



```

### Study Site Map ###

Now, we will construct a nice map of our study area with the associated occurrences as points and then improve our projection map from our model results. First, we will get a polygon of the state of Arkansas. We can pull a polygon of any state from the tigris package. If for some reason you need state data from specific years (i.e., not just the polygon), you can specify the year in the states function. Here, we just need the polygon for mapping purposes.

```{r}

arkansas = states() %>% 
  filter(NAME=='Arkansas')

# Lets check the projection

st_crs(arkansas)$proj4string

# Lets change the projection to match the flowlines

arkansas = st_transform(arkansas, st_crs(EnvFull))

```


Lets throw everything together for the small map (hint: it is very ugly at the moment).

```{r}
ggplot()+
  geom_sf(data = st_geometry(arkansas), fill = "white") +
  geom_sf(data = st_geometry(Basin), fill = "gray95") +
  geom_sf(data = st_geometry(EnvFull), color = "darkblue") +
  geom_sf(data = PBlocsSf)

```


Lets see what projection everything is in.

```{r}

crs(Basin, proj = T)
Basin = st_transform(Basin, st_crs(siteSf))
crs(Basin, proj = T)


crs(mississippi, proj = T)

st_crs(siteSf)$proj4string

crs(Rivers, proj = T)
Rivers = st_transform(Rivers, st_crs(mississippi))
crs(Rivers, proj = T)

crs(Lakes, proj = T)
Lakes = st_transform(Lakes, st_crs(mississippi))
crs(Lakes, proj = T)


```

Lets go zoomed out

```{r}
zoomedOut = ggplot()+
  geom_sf(data = mississippi, fill = "white", color = "black", linewidth = 0.5)+
  geom_sf(data = Basin, fill = "gray90", color = "black", linewidth = 0.1)

zoomedOut
```

Now to clean it up a little bit...

```{r}
zoomedOut = zoomedOut +
  theme_bw() +
  theme(axis.text.y = element_blank(), axis.text.x = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(color = "black"), panel.border = element_rect(colour = "black", fill = NA, linewidth = 1), plot.margin = margin(t = 0, r = 0, b = 0, l = 0))

zoomedOut
```

Lets go zoomed in

```{r}
zoomedIn = ggplot()+
  geom_sf(data = Basin, fill = "gray90", color = "black", linewidth = 0.5) 

zoomedIn
```

Clean it up...

```{r}
zoomedIn = zoomedIn+
  new_scale_fill()+
  theme_bw()+
  theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 0, vjust = 0.5, size = 10, color = "black"), axis.text.y = element_text(angle = 0, vjust = 0.5, size = 10, color = "black"), axis.line = element_line(color = "black"), panel.border = element_rect(colour = "black", fill = NA, linewidth = 1)) +
  scale_x_continuous(breaks = c(-91.0, -90.0, -89.0), labels = scales::label_number(accuracy = 0.1)) +
  scale_y_continuous(breaks = c(33.0, 34.0, 35.0), labels = scales::label_number(accuracy = 0.1))

zoomedIn
```

Now lets add a bunch of stuff to our blank canvas...

```{r}

zoomedIn = zoomedIn +
  geom_sf(data = Rivers, color = "black") +
  geom_sf(data = st_geometry(Lakes), color = "black", fill = "black") +
  geom_sf(data = siteSf, aes(pch=Description), fill='white', color = "black", size = 2) +
  scale_shape_manual(values=c(21, 22, 23), name='', labels = c("Receivers", "Stream Gauges", "Access Locations")) +
  geom_rect(aes(xmin = -90.27, xmax = -90.14, ymin = 33.5, ymax = 33.6), linewidth = 1, color = "black", fill = NA) +
  geom_rect(aes(xmin = -91.05, xmax = -90.80, ymin = 32.4, ymax = 32.6), linewidth = 1, color = "black", fill = NA) +
  annotation_scale(location = "bl", width_hint = 0.25, unit_category = "metric", style = "ticks") +
  theme(legend.position = "none") +
  annotation_north_arrow(location = "tl", which_north = "true", style = north_arrow_fancy_orienteering())
 

  
zoomedIn
```


### Putting the primary map together

```{r}

map_with_inset <-
  ggdraw(zoomedIn) +
  draw_plot(zoomedOut, x = 0.62, y = 0.06, width = 0.345, height = 0.40, halign = 0, valign = 0)

map_with_inset

## Note: the inset map does not look good at the moment, but that's because it got wonky later with ggarrange, so I have modified it to look better in the end product rather than now. This will come up several times later.
```

### Now lets break these apart to look at the upper and lower array specifically.

First, I don't think elevation raster is needed for these panels as the extent will all be in the floodplain, and thus, relatively small differences in elevation. Additionally, the map will not change in orientation, so additional north arrows are not needed. So, lets remake the zoomedIn map, but without elevation and north arrow...

```{r}
zoomedInClean = ggplot() +
  geom_sf(data = Basin, fill = "gray90", color = "black", linewidth = 1) +
  geom_sf(data = Rivers, color = "black", linewidth = 1) +
  geom_sf(data = st_geometry(Lakes), color = "black", fill = "black") +
  geom_sf(data = siteSf, aes(pch=Description), fill='white', color = "black", size = 3) +
  scale_shape_manual(values=c(21, 22, 23), name='', labels = c("Receivers", "Stream Gauges", "Access Locations")) +  annotation_scale(location = "bl", width_hint = 0.25, unit_category = "metric", style = "ticks") +
  theme_bw() + 
  theme(panel.grid = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, size = 10, color = "black"), axis.text.y = element_text(angle = 0, vjust = 0.5, size = 10, color = "black"), axis.line = element_line(color = "black"), panel.border = element_rect(colour = "black", fill = NA, linewidth = 1), legend.position = "none")


zoomedInClean
```

Now, lets isolate the upper array. We'll also label the rivers in this step (this was tedious, but I could not find an automated way that did not require creating additional data files with lat/long and labels for each river).


```{r}

upper_array <- zoomedInClean +
  theme(axis.text.y = element_blank(), axis.text.x = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(color = "black"), panel.border = element_rect(colour = "black", fill = NA, linewidth = 1)) +
  geom_text(x = -90.165, y = 33.58, aes(label = "Yalobusha River"), angle = 50, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_text(x = -90.20, y = 33.527, aes(label = "Yazoo River"), angle = 0, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_text(x = -90.232, y = 33.57, aes(label = "Tallahatchie River"), angle = 55, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_label(x = -90.165, y = 33.502, aes(label = "Upper Array"), angle = 0, size = 4.5, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  scale_x_continuous(limits = c(-90.27, -90.14)) +
  scale_y_continuous(limits = c(33.5, 33.6)) 

upper_array

```

Upper array looked good. How about the lower array...

```{r}

lower_array <- zoomedInClean  +
  theme(axis.text.y = element_blank(), axis.text.x = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(color = "black"), panel.border = element_rect(colour = "black", fill = NA, linewidth = 1)) +
  geom_text(x = -90.85, y = 32.475, aes(label = "Yazoo River"), angle = 40, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_text(x = -90.84, y = 32.53, aes(label = "Big Sunflower River"), angle = 60, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_text(x = -91.00, y = 32.563, aes(label = "Steele Bayou"), angle = 90, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_text(x = -91.01, y = 32.475, aes(label = "Eagle Lake"), angle = 350, size = 3, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  geom_label(x = -90.85, y = 32.405, aes(label = "Lower Array"), angle = 0, size = 4.5, family = "Times New Roman", fontface = "bold", check_overlap = TRUE) +
  scale_x_continuous(limits = c(-91.05, -90.8)) +
  scale_y_continuous(limits = c(32.4, 32.6))

lower_array

```

### Now, lets put it all together...

```{r}

final <- ggarrange(map_with_inset,                                                 # First row with basin
          ggarrange(upper_array, lower_array, nrow = 2, labels = NULL, align = "hv"), # Second col with confluences
          ncol = 2, 
          widths = c(1.8, 1.2),
          labels = NULL,
          align = "hv"
          ) 

final 

#ggsave(filename = "StudyAreaMap.tiff", plot = final, scale = 1, width = 7.25, height = 5.5, units = "in", dpi = "retina")

```

